# LFM2 Vision-Language 1.6B Q8_0 Model

This directory contains the LFM2 Vision-Language 1.6B quantized model.

## Model Information

- **Model**: LFM2 Vision-Language 1.6B Q8_0
- **Format**: GGUF (quantized)
- **Size**: ~1.6B parameters (quantized to 8-bit)
- **Use Case**: Vision-language understanding and generation

## Files Required

- `LFM2-VL-1.6B-Q8_0.gguf` - Main quantized model file

## Usage

This model provides:
- Vision-language understanding
- Image captioning
- Visual question answering
- Multimodal code analysis
- Document understanding with visual elements

## Quantization

The Q8_0 quantization provides:
- Reduced memory usage
- Faster inference
- Good quality retention
- Suitable for local deployment
